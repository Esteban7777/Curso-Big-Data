---
title: "Taller-1"
output:
  word_document: default
  html_document:
    citation_package: natbib
  pdf_document: default
date: "2024-02-07"
bibliography: bibliografia.bib
editor_options:
  markdown:
    wrap: 72
---

```{r echo=FALSE}
library(gridExtra)
library(rvest)
library(tidyverse)
library(zoo)
library(ggthemes)
library(boot)
library(caTools)
library(broom)
library(tibble)
library(knitr)

library(pacman)

p_load(rio, 
       tidyverse, 
        caret, 
        gridExtra, 
       skimr)    
```

```{r}
if (!requireNamespace("zoo", quietly = TRUE)) {
  install.packages("zoo")}
```

# 1. Introduccion

El objetivo de este informe es encontrar los determinantes del salario
de las personas encuestadas en Bogotá y realizar una predicción del
mismo. Encontrar los determinantes del salario es importante porque
proporciona una guía tanto en términos personales como de política
económica cuando se busca aumentar los ingresos de las personas. Desde
la perspectiva de la política económica, aumentar los ingresos reales de
las personas puede contribuir al mejoramiento de su calidad de vida. Por
lo tanto, si se conocen los factores que pueden aumentar su capacidad
adquisitiva, es importante desarrollar políticas públicas orientadas en
ese sentido. Por otro lado, el estudio de los determinantes del salario
también es útil para las personas que ya tienen un empleo y aspiran a
mejorar sus condiciones de vida. Si se encuentra, por ejemplo, que la
educación es clave, es en este ámbito donde el trabajador debe centrar
sus esfuerzos para mejorar.

Desde la teoría económica, la ecuación de Mincer es un punto de partida
para estudiar los determinantes del salario laboral. Este modelo estima
el impacto de un año adicional de estudios en las rentas laborales de
los individuos (Mincer, 1974). La ecuación tradicional de Mincer se
puede estimar mediante mínimos cuadrados ordinarios (MCO), utilizando
como variable dependiente los ingresos y como variables independientes
los años de educación, la experiencia laboral y el cuadrado de esta
última.

$$ln(w) = \beta_{0} + \beta_{1}S + \beta_{2}Exp + \beta_{3}Exp^2 + \epsilon$$
Donde: - $w$ son los ingresos del individuo. - $S$ es el número de años
de educación formal completada. - $\text{Exp}$ son los años de
experiencia laboral. - $\epsilon$ es el término de perturbación
aleatoria que se distribuye según una Normal
$\mathcal{N}(0, \sigma_{\epsilon}^2)$.

Para este estudio, se utilizará información de la Gran Encuesta
Integrada de Hogares (GEIH). Esta encuesta solicita información sobre
las condiciones de empleo de las personas y las características
generales de la población. Por lo tanto, tenemos los insumos necesarios
para encontrar los determinantes del salario.

Con base en lo anterior, podemos iniciar el análisis de las siguientes
variables:

-   Edad (Age)
-   Cuenta propia (Self-employed)
-   Estrato (Socioeconomic stratum)
-   Formal (Formal employment)
-   Horas trabajadas la semana pasada (Actualhours worked previous week)
-   Horas trabajadas habitualmente (Usual weeklyhours worked)
-   Informal (Informal employment)
-   Ingreso total (Totalincome)
-   Educación (Max. Education level attained)
-   Oficio (Occupation)
-   Experiencia (Experience)
-   Salario (Salary)
-   Sexo (Sex)
-   Horas trabajadas(Total hours worked)
-   Tamaño de la empresa (Company size)

# 2. Datos

## Lectura de los datos

El proceso para leer los datos consiste en hacer un web scraping a la
información que se encuentra en esta página web:
<https://ignaciomsarmiento.github.io/GEIH2018sample/.> Los datos están
particionados en 10 páginas diferentes, por lo cual se tiene que hacer
un proceso iterativo. En primer lugar, se guarda en la variable
**`url_base`** la dirección web de la que se debe extraer la
información. Hay un ligero cambio respecto a la URL general y este es
que las tablas se encuentran un poco más anidadas, por lo que se debe
completar la URL. Como la base de datos completa se encuentra separada
en 10 partes, el proceso se debe repetir el mismo número de veces.
Primero se crea una lista vacía llamada **`tables_list`**, en esta lista
se guarda la información extraída de la página en cada iteración. Dentro
del bucle **`for`**, se va modificando la ruta de extracción para que
haga un recorrido por todas las direcciones donde se encuentran los
datos. Esto es relativamente sencillo debido a que lo único que cambia
es el número de la página; por esto, el iterador es un entero.

Cuando se hace el proceso iterativo en las 10 páginas, estas quedan
anidadas en la lista vacía **`tables_list`**. Para darle un formato
manejable en el proceso de machine learning, se concatenan en una sola
sabana de datos con formato **`tibble`**. Como la cantidad de datos es
considerable, este proceso dura aproximadamente 8 minutos.

```{r}
t1<-Sys.time()

url_base<-my_url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"

tables_list <- list()
for (i in 1:10){
 bucle_url<-paste0(url_base, i, ".html")
 my_html=read_html(bucle_url)
 table<-my_html %>% html_table()
 tables_list[[i]] <- table}

data<-dplyr::bind_rows(tables_list)
t2<-Sys.time()
Tiempo_ejecucion<-t2-t1
Tiempo_ejecucion
```

## Preprocesamiento de datos

La estrategia propuesta para conservar la representatividad de la
muestra que permite el factor de expansión consiste en transformar esta
variable en un factor de ponderación de manera que conservemos su
proporción con respecto al universo sin afectar el tamaño original de la
muestra, de esta manera se ahorra recursos computacionales la ejecución
de los algoritmos y el tratamiento de los datos.

```{r}
base_no_ponderada<-length(data$fex_c)
universo_representado<-sum(data$fex_c)

data<-  data %>%
  mutate(data, peso=fex_c/universo_representado) %>% 
  mutate(data,fponderacion=peso*base_no_ponderada)

base_ponderada<-sum(data$fponderacion)
unidades_muestrales_fex<-length(unique(data$fex_c))
unidades_muestrales_fpon<-length(unique(data$fponderacion))

tabla1<-t(tibble(base_no_ponderada,base_ponderada,unidades_muestrales_fex,unidades_muestrales_fpon,universo_representado))
tabla1
```

Para trabajar con los datos ponderados se replica cada registro tantas
unidades muestrales represente.

```{r}
data_ponderada<-uncount(data,weights = round(data$fponderacion))
base_ponderada<-length(data_ponderada$directorio)
base_ponderada
base_no_ponderada
```

El preprocesamiento de los datos se realiza de forma simultánea con el
análisis descriptivo. Esto se debe a que, generalmente, al analizar la
distribución de cada variable de forma individual, se logra identificar
registros vacíos o atípicos que merecen un tratamiento aparte. Sin
embargo, aplicamos unas reglas de validación iniciales para garantizar
que los modelos de regresión tengan resultados satisfactorios. Primero,
se cambiaron los nombres de las variables que se van a usar para que su
identificación sea más sencilla. También se les dio el formato adecuado
de tal forma que se respetara la naturaleza cualitativa o cuantitativa
de las mismas. Los filtros más importantes de la base de datos fueron
para la población en edad de trabajar. Como sugerencia del ejercicio,
solo hay registros para personas mayores de edad. También se filtran las
personas que están activas en el mercado laboral, ya que son estas las
únicas que perciben un salario.

```{r}
# Limpieza de mayores de edad: Este chunk lo usamos solo como limpieza de datos 


## Falta filtrar solo por personas 
data_ponderada <- data_ponderada %>%
    rename(
      Edad= age,
      Estrato=estrato1,
      Ingreso=ingtot,
      Educacion=p6210,
      Experiencia= p6426,
      Salario=y_total_m,
      Sexo=sex,
      Horas_trabajadas=totalHoursWorked
  )  

data_ponderada <- data_ponderada %>%
    mutate(
      across(c(cuentaPropia,Estrato,formal,informal,maxEducLevel,oficio,Educacion,Sexo,microEmpresa),as.character) 
  )
### Filtro por población economica activa

data_ponderada <- data_ponderada %>%
  filter(Edad >18 & dsi !="1") 


data_ponderada <-data_ponderada %>%
  filter(p6240==1)

```

## Análisis exploratorio de datos individual

Para que la manipulación de los datos sea más sencilla, se tomará del
dataframe original solo las columnas que se establecieron en la
introducción y se guardarán en el dataframe **`datah`**.

```{r}
data_h <- data_ponderada %>%
  select(Edad,cuentaPropia,Estrato,formal,informal,maxEducLevel,oficio,Educacion,Experiencia,Salario,Sexo,Horas_trabajadas,directorio,microEmpresa)

data_h <- data_h %>%
  mutate(Sexo = ifelse(Sexo == 1, 0, ifelse(Sexo == 0, 1, Sexo)))


data_h$maxEducLevel <- na.aggregate(data_h$maxEducLevel, FUN = function(x) {
  moda <- names(sort(table(x), decreasing = TRUE))[1]
  return(moda)
})
```

Después de depurar los datos, revisamos cuántos valores faltantes hay en
la variable salario. Evidenciamos una cantidad considerable de valores
NA, por lo tanto, procedemos a realizar la imputación de estos con el
promedio del salario del directorio de cada hogar.

```{r}
summary(data_h$Salario)
```

```{r}
data_h = data_h %>% 
     group_by(directorio) %>% 
     mutate(mean_salario = mean(Salario, na.rm=T))

data_h = data_h %>%
     mutate(Salario2 = ifelse(test = is.na(Salario)==T,
                               yes = mean_salario,
                               no = Salario))
table(is.na(data_h$Salario2))
```

Se identifica que hay personas que reportaron ingresos iguales a cero a
pesar de ser trabajadores y haber reportado horas laboradas, razón por
la cual se excluyen estos registros de la muestra.

```{r}
data_h <-data_h %>%
filter(Salario2>0)

table(is.na(data_h$Salario2))
```

Para visualizar la distribución individual de las variables con más
precisión, se dividen en dos grupos tomando como referencia su
naturaleza, es decir, si son cualitativas o cuantitativas. En primer
lugar, se muestra una gráfica con la escala normal del salario y en base
logarítmica. De esta forma, se observa una distribución más uniforme de
la variable y la interpretación de los determinantes de naturaleza
cuantitativa se hará desde las elasticidades.

```{r}
data_h<-data_h %>% mutate(log_salario=log(Salario2),
                            Edad2=Edad^2
                            )
par(mfrow=c(1,2))  
hist(data_h$Salario2, main="Distribución del salario", xlab="Salario", ylab="Frecuencia")
hist(data_h$log_salario, main="Histograma de logaritmo del Salario", xlab="Log(Salario)", ylab="Frecuencia")
```

```{r}
summary_salario <- summary(data_h$Salario)
summary_salario
```

Para el año 2018, el salario mínimo en Colombia era de \$781.242, por lo
que la mayoría de las personas que hicieron parte de este estudio y que
trabajan ganan al menos un salario mínimo. Históricamente, según el
DANE, la tasa de informalidad en Bogotá ha estado ubicada alrededor del
40%. Comparando esta cifra con las personas que reportan el salario,
asumiendo su representatividad, se puede ver que, en términos nominales,
el salario del sector formal está muy cerca de la retribución en el
mercado informal. Sin embargo, para este análisis se debe tener en
cuenta que el salario mínimo solo es una parte de los costos laborales y
que, a pesar de que estén cercanos los salarios con los beneficios de un
salario integral, como la afiliación a EPS, pensión y cesantías, la
brecha puede ser mayor. Para identificar el comportamiento de las
variables que sirven para explicar el comportamiento del salario, se
dividen en 2 categorías según su naturaleza de medición en cualitativas
y cuantitativas. Los resultados más interesantes se ven en la variable
del Estrato; en este caso, se observa cómo la mayoría de personas
encuestadas se ubican en los estratos 2 y 3, con una representación del
42.9% y 37.2% respectivamente. La clasificación de las personas a través
de los estratos tiene el propósito de identificar la capacidad
adquisitiva. Por tanto, en esta encuesta predominan personas con
ingresos medio-bajos siguiendo las definiciones del estrato
socioeconómico. Las diferencias de representación por sexo no son
significativas y siguen la regla general de las cifras poblacionales en
Colombia.

Las cifras de las condiciones de las personas en el mercado laboral son
consistentes, sobre todo en la condición de formalidad. Para el año
2018, el 63.3% reporta que se encuentra trabajando en el sector formal.
La formalidad en este estudio se define como la persona que está
afiliada a la seguridad social. Desde la teoría, se espera que las
personas en el sector formal perciban salarios mayores a las personas en
condiciones de informalidad.

```{r}
qualitative_factor_vars <- data_h %>%
  select(where(function(x) is.factor(x) || is.character(x))) 
plot_proportion <- function(column, col_name) {
  proportion <- prop.table(table(column)) * 100
  barplot(proportion, main = col_name, ylab = "Proporción (%)", col = "skyblue", ylim = c(0, 100))
  text(x = 1:length(proportion), y = proportion, 
       label = paste0(round(proportion, 1), "%"), pos = 3, cex = 0.8, col = "black")
}
num_vars <- ncol(qualitative_factor_vars)
num_rows <- ceiling(sqrt(num_vars))
num_cols <- ceiling(num_vars / num_rows)
par(mfrow = c(num_rows, num_cols), mar = c(5, 5, 2, 2))  
walk2(qualitative_factor_vars, names(qualitative_factor_vars), plot_proportion)
```

La distribución individual de las variables cuantitativas se muestra a
continuación. El comportamiento de la edad es bastante uniforme y la
mayor concentración se encuentra alrededor de los 37 años. Siguiendo la
teoría del ciclo de vida, la mayoría de las personas encuestadas se
encuentran en una edad adulta temprana. En el aspecto laboral, esto
significa que ya se encuentran en un momento de estabilidad y donde son
más productivas, y los salarios deberían ser más altos ya que se cuenta
con más experiencia.

Este argumento se contrasta con los datos de experiencia en su trabajo,
que se miden a partir de los meses que llevan trabajando en la misma
empresa. Los datos muestran que, en promedio, las personas llevan
trabajando en el mismo lugar 5 años. Sin embargo, la diferencia con la
mediana es muy alta, ya que el valor medio de los meses trabajados es 2
años. Esta distorsión se puede explicar por la presencia de datos
atípicos.

Por el lado de las horas trabajadas la semana pasada, sus valores están
muy cercanos a las exigidas por la legislación laboral colombiana.

```{r}
quantitative_vars <- data_h %>%
  select(where(is.numeric))

plot_histogram <- function(column, col_name) {
  hist(column, main = col_name, xlab = col_name, ylab = "Frecuencia", col = "skyblue")
}

num_vars <- ncol(quantitative_vars)
num_rows <- ceiling(sqrt(num_vars))
num_cols <- ceiling(num_vars / num_rows)

par(mfrow = c(num_rows, num_cols), mar = c(5, 5, 2, 2))  

walk2(quantitative_vars, names(quantitative_vars), plot_histogram)
```

## Análisis exploratorio bivariado

\
En este apartado se explorarán las diferencias que pueden existir entre
las categorías analizadas en la sección anterior cuando se presentan a
través del logaritmo del salario. Las diferencias más grandes se
observan a través de la variable Estrato Socioeconómico y en el nivel de
educación cuando el encuestado cuenta con grado de educación superior.

Las diferencias a través del estrato se intuyen por la naturaleza de
esta variable, ya que mide, entre otras cosas, la capacidad adquisitiva
del hogar. Mientras tanto, el tema del estudio se explica por la teoría
del capital humano, que sostiene que la formación de los individuos son
inversiones que aumentan su productividad e ingresos a lo largo del
tiempo.

Se observan diferencias moderadas a través de variables como si el
encuestado trabaja por cuenta propia o si está desempeñando su trabajo
en condiciones de informalidad. Los datos muestran un ligero aumento del
salario promedio si la persona trabaja como empleada. Además, los
trabajadores que trabajan como empleados formales perciben unos ingresos
ligeramente mayores que los trabajadores informales. No se observan
diferencias en el caso del sexo, donde los salarios son uniformes para
hombres y mujeres.

```{r}
options(repr.plot.width = 20, repr.plot.height = 10)
qualitative_vars <- data_h %>% select(where(is.factor) | where(is.character))
num_cols <- 4
num_rows <- ceiling(ncol(qualitative_vars) / num_cols)
par(mfrow = c(num_rows, num_cols))
for (col in colnames(qualitative_vars)) {
  suppressWarnings(boxplot(log_salario ~ data_h[[col]], data = data_h, main = col, xlab = col, ylab = "log_salario"))
}
```

En relación a las variables de naturaleza cuantitativa, no se observan
patrones que ayuden a determinar cambios significativos en el ingreso
laboral. Incluso, los niveles de correlación entre las variables no
muestran señales de que puedan aportar cuando se inicie con el proceso
de modelación.

```{r}
options(repr.plot.width = 20, repr.plot.height = 10)

# Seleccionar variables cuantitativas
numeric_vars <- data_h %>% select(where(is.numeric))

# Establecer el número de columnas para la disposición de la grilla
num_cols <- 4
num_rows <- ceiling(ncol(numeric_vars) / num_cols)

# Establecer el tamaño de la gráfica
par(mfrow = c(num_rows, num_cols))

# Crear scatter plots para variables cuantitativas
for (col in colnames(numeric_vars)) {
  suppressWarnings(plot(data_h[[col]], data_h$log_salario, main = col, xlab = col, ylab = "log_salario"))
}
```

# 3. Análisis de regresion

EL propósito es estimar el siguiente modelo:

$$log(w) = \beta_{1} + \beta_{2}Edad + \beta_{3}Edad^2$$

```{r}
modelo1<-lm(log_salario ~  Edad + Edad2,
data=data_h)
stargazer::stargazer(modelo1,type = "text")
```

Los coeficientes de la regresión son significativos hasta a un nivel de
confianza del 95%. A partir de ellos podemos rescatar la siguiente
ecuación de salarios en función de la edad

$$log(w) = 12.786 + 0.64 Edad - 0.001 Edad^2 + u$$

Se evidencia que el ajuste del modelo dentro de la muestra no es muy
grande ya que el R2 es de 0.032. Esta medida también la podemos
complementar con el cálculo el error cuadrático medio MSE.

```{r}
fit<-predict.lm(modelo1,newdata = data_h)
data_h$log_salario_gorro<-fit
MSE<-sum((data_h$log_salario-data_h$log_salario_gorro)^2)/length(data_h$log_salario)
MSE
```

Aumentando la complejidad del modelo es probable que tanto el R2 aumente
como el MSE se reduzca, sin embargo, con esto estaremos aumentando la
varianza de los estimadores, lo que permite disminuir el sesgo.

A partir de los coeficientes obtenidos es posible calcular la edad pico
en el crecimiento de los ingresos de las personas.

$$\frac {\partial log(w)}{\partial Edad} =0 $$

$$\frac {\partial log(w)}{\partial Edad} = \beta 1-(2) \beta2Edad=0$$

$$Edad^*=\frac {\beta1}{-(2)\beta 2}$$

Calculamos la edad pico, al tiempo que construimos la función que nos
permitirá mediante el bootstrap estimar la varianza de los estimadores
para la generación del intérvalo de confianza.

```{r}

bfuncion<-function(data,index){
  
modelo<-lm(log_salario ~  Edad + Edad2, data=data_h,subset = index)

coeficientes<-modelo$coefficients

b1<-coeficientes[2]
b2<-coeficientes[3]

edad_pico<-b1/(-2*b2)
return(edad_pico) #returns the second coefficient of the linear regression
}

edad_pico<-bfuncion(data_h,1:nrow(data_h))
modelo1$coefficients[2]/(-2*modelo1$coefficients[3])
edad_pico
```

Para poder realizar esta inferencia calculamos la Varianza utilizando
bootstap.

```{r}
set.seed(123)
repeticiones<-1000
boot(data_h,bfuncion,R=repeticiones)
```

Con esto podemos establecer el intervalo de confianza para la edad pico

$$Edad^* \pm t_{\alpha/2} * 0.3462259$$

Es decir que para un nivel de confianza del 95%

```{r}
n=nrow(x = data_h)
t=abs(qt(p = (1-0.95)/2,df =n-1 ))
limite_inferior=edad_pico-(t*0.3462259)
limite_superior=edad_pico+(t*0.3462259)
limites<-c(limite_inferior,limite_superior)
limites
```

Observamos de manera gráfica el ajuste del modelo a los datos.

```{r}
data_aux<-data_h %>% select(log_salario,log_salario_gorro,Edad)

data_aux<-data_aux %>%  pivot_longer(cols = log_salario:log_salario_gorro,
names_to = "Predict",
values_to = "Valor")

ggplot(data_aux,aes(x=Edad,color=Predict)) +
geom_point(aes(y=Valor)) +
labs(title = "Ajuste del modelo a los datos de la muestra",
x="Edad",
y="Log salario"
) +
theme_stata() +
scale_fill_stata()
```

# 4. Modelo de género

$$log(w) = \beta_{1} + \beta_{2}Mujer$$a) Estimación del modelo general.

```{r}
modelS<-lm(log_salario ~Sexo,data=data_h)
stargazer::stargazer(modelS,type = "text")
```

En el modelo general, al estimar el logaritmo natural del salario contra
el sexo de la persona, se observa que las mujeres, en promedio, ganan
menos que los hombres. La relación es estadísticamente significativa y
el parámetro -0.068 indica que por ser mujer se espera que el logaritmo
natural del salario disminuya 0.068 unidades en promedio. Esta relación
es estadísticamente significativa y valida la hipótesis muy trabajada en
el mercado laboral que muestra que hay diferencias significativas en las
ganancias entre hombres y mujeres.

Aplicación del teorema FWL:

Para la aplicación del teorema de FWL se siguen dos pasos. En primer
lugar, se estima un modelo donde la variable de interés, en este caso el
género de la persona encuestada, se deja como variable independiente
frente a las variables de control y se toman los residuales.

Luego se estima el segundo modelo donde la variable independiente es el
logaritmo del salario frente a las variables de control y se toman los
residuales. Por último, se estima la regresión de los dos residuales.

Se espera que el parámetro estimado en el primer modelo sea igual a la
estimación del modelo en los residuales.

Para esto se incluyen las siguientes variables de control:

-   Edad

-   Oficio

-   Si trabaja en microempresa

-   Educación formal

El objetivo de esta estimación no es encontrar los determinantes del
salario como se hizo en la primera parte, sino entender las diferencias
en salario que se pueden presentar a través del sexo de las personas.
Por esto se incluyeron estas variables que pueden controlar mejor el
sesgo de solo incluir el sexo.

Paso 1: Estimar la ecuación del género de las personas contra las
variables de control y tomar los residuales.

```{r}
resid1 <- lm(Sexo ~Estrato+oficio+Edad+Edad2+informal+maxEducLevel+microEmpresa,data = data_h)$residuals
```

Paso 2: Se estima el salario solo frente a las variables de control y se
toman los residuales.

```{r}
resid2 = lm(log_salario ~Estrato+oficio+Edad+Edad2+informal+maxEducLevel+microEmpresa,data = data_h)$residuals
```

```{r}
general<-lm(log_salario ~Estrato+oficio+Edad+Edad2+informal+maxEducLevel+microEmpresa+Sexo,data = data_h)
mod_resid=lm(resid2~resid1)
```

```{r}
stargazer::stargazer(general,mod_resid,modelS,type = "text",digits= 3)
```

Luego de aplicar el teorema de FWL se observa cómo los coeficientes
estimados son iguales, por lo que se valida utilizar las variables de
control que se han venido trabajando.

A través de las tres especificaciones se ha comprobado que existen
diferencias en el salario entre hombres y mujeres. Desde la estimación
se observa que las mujeres, en promedio, ganan menos que los hombres en
condiciones de empleo iguales. En el primer modelo general, cuando no se
incluyen variables de control, se nota cómo en promedio las mujeres
ganan 0.06 unidades menos que los hombres, y cuando se incluyen
variables de control la diferencia es de 0.09 unidades en el logaritmo
del salario.

# 5 Predicción

Las especificaciones que se van a trabajar para el proceso de predicción
se van a construir tomando como referencia la ecuación de Mincer.

$$Ln(w) = \beta_{0} +* \beta_{1}S + \beta_{2}Exp +* \beta_{3}Exp^2 +
\epsilon$$

2.  Tomando los elementos de la ecuacion de mince pero anadiendo las
    variables propuestas desde el punto de vista empirico

$$Ln(w) = \beta_{0} + \beta_{1}Edad + \beta_{2}edad^2 + \beta_{3}Cuentapropia + +\beta_{4}Estrato+ \beta_{5}informal+ \beta_{6}Educacion + \beta_{7}sexo+ \beta_{8}Microempresa+ \beta_{9}Horas_trabajadas + \beta_{10}oficio +\epsilon$$

3.  Modelo del punto 3 donde solo se tenia en cuenta la edad

$$ ln(w)=\beta_{0} + \beta_{1}Edad + \beta_{2}edad^2 $$

Luego de estas estimaciones se estiman otros modelos derivados de los
generales, aplicando alguna complejidad al modelo y poder estimar de
mejor forma los determinantes del salario.

a)  Particion de los datos

```{r}
set.seed(10101)

train_size <- floor(0.7 * nrow(data_h))


train_indices <- sample(1:nrow(data_h), size = train_size, replace = FALSE)


train <- data_h[train_indices, ]


test <- data_h %>%
  filter(!row_number() %in% train_indices)


niveles_oficio <- unique(c(train$oficio, test$oficio))


train$oficio <- factor(train$oficio, levels = niveles_oficio)
test$oficio <- factor(test$oficio, levels = niveles_oficio)
```

b)  Estimacion de los modelos

```{r}
mod1 = lm(log_salario~ maxEducLevel+Experiencia+Experiencia^2,data = train)
mod2 = lm(log_salario~ Edad+Edad^2+cuentaPropia+Estrato+informal+Sexo+Experiencia+Experiencia^2+microEmpresa+Horas_trabajadas+oficio,data = train)
mod3 = lm(log_salario~ Edad+Edad^2,data = train)
mod4 = lm(log_salario~ Edad+Edad^2+Experiencia+Experiencia^2,data = train)
mod5 =lm(log_salario~ Edad+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas,data = train)
mod6 =lm(log_salario~ Edad+Experiencia+Horas_trabajadas,data = train)
mod7 =lm(log_salario~ Edad+Edad^2+Experiencia+Horas_trabajadas,data = train)
mod8 =lm(log_salario~ Edad+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas++cuentaPropia,data = train)
mod9 =lm(log_salario~ Edad+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas+informal,data = train)
mod10 =lm(log_salario~ Edad+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas+Sexo,data = train)

mod11 =lm(log_salario~ Edad*maxEducLevel+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas+Sexo,data = train)

mod12 =lm(log_salario~ Edad+Edad^2+Experiencia*maxEducLevel+Experiencia^2+Horas_trabajadas+Sexo,data = train)

mod13 =lm(log_salario~ Edad*maxEducLevel+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas+Sexo+oficio,data = train)

mod14 =lm(log_salario~ Edad+Edad^2+Experiencia*maxEducLevel+Experiencia^2+Horas_trabajadas+Sexo,data = train)

mod15 =lm(log_salario~ Edad+Edad^2+Experiencia*maxEducLevel+oficio+Horas_trabajadas+Sexo,data = train)

mod16 = lm(log_salario~ oficio,data = train)
mod17 = lm(log_salario~ oficio+Edad+Edad^2,data = train)
mod18 = lm(log_salario~ oficio+Edad+Edad^2+Sexo,data = train)
```

```{r}
calculate_metrics <- function(model, test_data) {
  metrics <- glance(model)
  predictions <- predict(model, newdata = test_data)
  rmse <- sqrt(mean((predictions - test_data$log_salario)^2))
  error_train <- sqrt(mean(residuals(model)^2))
  return(c(metrics$r.squared, rmse, error_train))
}

models <- list(mod1, mod2, mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11,mod12,mod13,mod14,mod15,mod16,mod17,mod18)


model_names <- c("Modelo 1", "Modelo 2", "Modelo 3","Modelo 4","Modelo 5","Modelo 6","Modelo 7","Modelo 8","Modelo 9","Modelo 10","Modelo 11","Modelo 12","Modelo 13","Modelo 14","Modelo 15","Modelo 16","Modelo 17","Modelo 18")


metrics_list <- vector("list", length(models))


for (i in seq_along(models)) {
  metrics_list[[i]] <- calculate_metrics(models[[i]], test)
}


metrics_table <- tibble(
  Modelo = model_names,
  R2 = sapply(metrics_list, "[[", 1),
  Error_Test = sapply(metrics_list, "[[", 2),
  Error_Train = sapply(metrics_list, "[[", 3)
)

```

```{r}
metrics_table %>% arrange(Error_Train)
```

c)  Discusion de los resultados

El modelo con menor error en prediccion es el modelo mas general, el que
se construyo a partir de las referencias teoricas y empiricas en los
anteriores capitulos. La razon principal es porque tiene en cuenta todas
estas variables y tambien porque captura muy bien todos los fenomenos
analizados que pueden tener a la hora de explicar los salarios.

```{r}
plot(residuals(mod2))
```

```{r}
train$res = residuals(mod2)

observaciones_alejadas <- train %>% 
  arrange(desc(abs(res))) %>%
  slice_head(n = 10)

observaciones_alejadas
```

```{r}
predicciones_train <- predict(mod2, newdata = train)
errores_train <- train$log_salario - predicciones_train
umbral_train <- 1.5 * IQR(errores_train)  
valores_atipicos_train <- which(abs(errores_train) > umbral_train)

print(train[valores_atipicos_train[1:5], ])
```

Con este metodo identificamos las personas en los que el modelo se
equivocp mas, para esto el modelo sobreestimo el salario , es decir que
hizo la prediccion por encima de los esperado.

Cuando se analizan los 5 mas significativos se puede ver claramente que
son personas que reportan que trabajan en condiciones precarias, el
salario es muy bajo, son mujeres , trabajan en el secotr informal y su
nivel de estudios es bajo.

Como al final el modelo de regresion, es un modelo sobre la media
influyen mucho todos los demas, por lo que la sobreestimacion del
salario que se da en este caso es normal. Es necesairo estimar con otro
tipos de modelos mas flexibles que logren interpretar mucho mejor estos
casos.

```{r}
#ctrl <- trainControl(
  #method = "LOOCV")

#es3 <- log_salario~ Edad+Edad^2+cuentaPropia+Estrato+informal+Sexo+Experiencia+Experiencia^2+microEmpresa+Horas_trabajadas+oficio

#odelo1c <- train(es3,
                 # data = data_h,
                 # method = 'lm', 
                  #trControl= ctrl)
```

Cuando se realiza la estimacion del error de test mediante LOOCV muestra
un error de estimacion de 0.47 el cual es inferior cuando se hacer por
medio de el primer metodo, es costoso en memoria pero da una clave para
entender que el error de la prediccion puede mejorar.

```{r}
#ctrl <- trainControl(
#method = "LOOCV")

#es13 <- log_salario~ Edad*maxEducLevel+Edad^2+Experiencia+Experiencia^2+Horas_trabajadas+Sexo+oficio

#odelo2c <- train(es13,
               # data = data_h,
               # method = 'lm', 
               # trControl= ctrl)
```

# Bibliografía

Mincer, J (1974), Schooling, experience and earnings, national bureau of
economic research, New York.
